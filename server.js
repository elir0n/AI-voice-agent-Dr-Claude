import express from "express";
import dotenv from "dotenv";
import OpenAI from "openai";
import multer from "multer";
import cors from "cors";
import fs from "fs";
import ffmpeg from "fluent-ffmpeg";
import ffmpegPath from "ffmpeg-static";
import { v4 as uuidv4 } from "uuid";
import { generateAvailableAppointments } from "./src/services/appointmentService.js";
import { saveLog, getLogs } from "./src/services/logService.js";
import { agentPrompt } from "./src/rules/agentPrompt.js";
import { detectLanguage } from "./src/utils/languageDetection.js";
import { textToSpeech } from "./src/services/ttsService.js";
import { OdoroService } from "./src/services/odoroService.js"; // âœ…

dotenv.config();
const app = express();
app.use(express.json());
app.use(cors());
app.use(express.static("public"));

ffmpeg.setFfmpegPath(ffmpegPath);

const UPLOAD_DIR = process.env.UPLOAD_DIR || "uploads";
const RESPONSES_DIR = process.env.RESPONSES_DIR || "responses";
if (!fs.existsSync(UPLOAD_DIR)) fs.mkdirSync(UPLOAD_DIR);
if (!fs.existsSync(RESPONSES_DIR)) fs.mkdirSync(RESPONSES_DIR);

const upload = multer({ dest: `${UPLOAD_DIR}/` });
const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const PORT = process.env.PORT || 3000;

// ðŸ§  × ×™×”×•×œ ×©×™×—×•×ª ×¤×¢×™×œ×•×ª
const sessions = new Map();

// ðŸ§¹ × ×™×§×•×™ sessions ×œ× ×¤×¢×™×œ×™× ×›×œ 3 ×“×§×•×ª
setInterval(() => {
  const now = Date.now();
  for (const [id, session] of sessions.entries()) {
    const last = session.lastActive || now;
    if (now - last > 3 * 60 * 1000) {
      sessions.delete(id);
      console.log(`ðŸ§¹ ×ž×—×§×ª×™ session ×œ× ×¤×¢×™×œ: ${id}`);
    }
  }
}, 60 * 1000);

// ðŸ“… ×”×¦×’×ª ×ª×•×¨×™× ×œ×“×•×’×ž×”
app.get("/appointments", (req, res) => res.json(generateAvailableAppointments()));
// ðŸ“œ ×”×¦×’×ª ×œ×•×’×™×
app.get("/logs", (req, res) => res.json(getLogs()));

// ðŸ§­ ×–×™×”×•×™ intent ×‘×¡×™×¡×™
function detectIntent(text) {
  const lower = text.toLowerCase();
  if (lower.includes("×œ×§×‘×•×¢") || lower.includes("×ª×•×¨ ×—×“×©") || lower.includes("book"))
    return "book_appointment";
  if (lower.includes("×œ×‘×˜×œ") || lower.includes("×œ× ×œ×”×’×™×¢") || lower.includes("cancel"))
    return "cancel_appointment";
  if (lower.includes("×œ×©× ×•×ª") || lower.includes("×œ×”×§×“×™×") || lower.includes("reschedule"))
    return "reschedule_appointment";
  return "general";
}

// ðŸŽ¤ × ×§×•×“×ª ×”×›× ×™×¡×” ×”×¨××©×™×ª ×œ×©×™×—×•×ª ×§×•×œ×™×•×ª
app.post("/voice", upload.single("audio"), async (req, res) => {
  const inputPath = req.file.path;
  const outputPath = `${inputPath}.mp3`;
  const sessionId = req.body.sessionId || uuidv4();

  try {
    // ðŸŽ§ ×”×ž×¨×” ×œ-MP3
    await new Promise((resolve, reject) => {
      ffmpeg(inputPath)
        .toFormat("mp3")
        .on("end", resolve)
        .on("error", reject)
        .save(outputPath);
    });

    // ðŸ—£ï¸ Speech â†’ Text
    const transcription = await client.audio.transcriptions.create({
      file: fs.createReadStream(outputPath),
      model: "whisper-1",
    });
    const text = transcription.text.trim();
    console.log(`ðŸŽ™ï¸ [${sessionId}] ×ž×©×ª×ž×© ××ž×¨: ${text}`);

    // ðŸŒ ×–×™×”×•×™ ×©×¤×”
    const detectedLang = await detectLanguage(text);

    // ðŸ§  × ×™×”×•×œ ×©×™×—×”
    if (!sessions.has(sessionId)) {
      sessions.set(sessionId, {
        messages: [
          { role: "system", content: agentPrompt },
          { role: "assistant", content: "×©×œ×•×, ×× ×™ ×”×¢×•×–×¨ ×”×§×•×œ×™ ×©×œ ×“\"×¨ ×§×œ×•×“ ×¤×™×§××¨. ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?" },
        ],
        lastActive: Date.now(),
      });
    }

    const session = sessions.get(sessionId);
    session.messages.push({ role: "user", content: text });
    session.lastActive = Date.now();

    // ðŸ§­ ×–×™×”×•×™ intent
    const intent = detectIntent(text);
    console.log(`ðŸ§  Intent detected: ${intent}`);

    // ðŸ§© ×¤×¢×•×œ×•×ª ×œ×¤×™ intent
    if (intent === "book_appointment") {
      const slots = await OdoroService.getAvailability();
      const free = slots.slots.filter(s => s.status === "free").slice(0, 3);
      const slotList = free.map(s => s.start.slice(11, 16)).join(", ");
      const reply = `×™×© ×ª×•×¨×™× ×¤× ×•×™×™× ×‘×™×•× ${slots.date} ×‘×©×¢×•×ª ${slotList}. ×‘××™×–×• ×©×¢×” × ×•×— ×œ×š?`;

      const audioBuffer = await textToSpeech(reply);
      saveLog({ sessionId, language: detectedLang, userText: text, reply, inputAudio: inputPath });
      res.setHeader("Content-Type", "audio/mpeg");
      return res.send(audioBuffer);
    }

    if (intent === "cancel_appointment") {
      const reply = "××•×§×™×™, ×× ×™ ×ž×‘×˜×œ ××ª ×”×ª×•×¨ ×©×œ×š. ×”×× ×ª×¨×¦×” ×œ×§×‘×•×¢ ×ª×•×¨ ×—×“×© ×‘×ž×§×•×?";
      const audioBuffer = await textToSpeech(reply);
      saveLog({ sessionId, language: detectedLang, userText: text, reply, inputAudio: inputPath });
      res.setHeader("Content-Type", "audio/mpeg");
      return res.send(audioBuffer);
    }

    if (intent === "reschedule_appointment") {
      const slots = await OdoroService.getAvailability();
      const alt = slots.slots.filter(s => s.status === "free").slice(0, 2);
      const altList = alt.map(s => s.start.slice(11, 16)).join(", ");
      const reply = `××™×Ÿ ×‘×¢×™×”. ×™×© ×ª×•×¨×™× ×—×œ×•×¤×™×™× ×‘×©×¢×•×ª ${altList}. ××™×–×” ×ž×”× × ×•×— ×œ×š ×™×•×ª×¨?`;

      const audioBuffer = await textToSpeech(reply);
      saveLog({ sessionId, language: detectedLang, userText: text, reply, inputAudio: inputPath });
      res.setHeader("Content-Type", "audio/mpeg");
      return res.send(audioBuffer);
    }

    // ðŸ¤– ××™×Ÿ intent ×‘×¨×•×¨ â†’ × ×©×œ×— ×œ-GPT
    const completion = await client.chat.completions.create({
      model: "gpt-4o",
      messages: session.messages,
    });
    const reply = completion.choices[0].message.content.trim();
    console.log(`ðŸ¤– [${sessionId}] GPT: ${reply}`);
    session.messages.push({ role: "assistant", content: reply });

    // ðŸ’¾ ×©×ž×™×¨×ª ×œ×•×’×™×
    const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
    const responseAudioPath = `${RESPONSES_DIR}/response_${timestamp}.mp3`;
    const responseTextPath = `${RESPONSES_DIR}/response_${timestamp}.txt`;
    const audioBuffer = await textToSpeech(reply, outputPath);

    fs.writeFileSync(responseAudioPath, audioBuffer);
    fs.writeFileSync(
      responseTextPath,
      `ðŸ•“ ${new Date().toLocaleString("he-IL")}\nðŸŒ ×©×¤×”: ${detectedLang}\nðŸŽ¤ ×ž×©×ª×ž×©: ${text}\nðŸ¤– GPT: ${reply}\n-------------------------------------\n`,
      { encoding: "utf-8" }
    );
    saveLog({ sessionId, language: detectedLang, userText: text, reply, inputAudio: inputPath, outputAudio: responseAudioPath });

    res.setHeader("Content-Type", "audio/mpeg");
    res.send(audioBuffer);

  } catch (error) {
    console.error("âŒ Voice processing error:", error);
    const fallbackMessage = "×ž×¦×˜×¢×¨, ×§×¨×ª×” ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×‘×§×©×”.";
    const fallbackAudio = await textToSpeech(fallbackMessage);
    res.setHeader("Content-Type", "audio/mpeg");
    res.status(500).send(fallbackAudio);
  } finally {
    try {
      [inputPath, outputPath].forEach(p => fs.existsSync(p) && fs.unlinkSync(p));
    } catch (e) {
      console.warn("âš ï¸ cleanup error", e);
    }
  }
});

app.listen(PORT, () => console.log(`ðŸš€ Server running on http://localhost:${PORT}`));
